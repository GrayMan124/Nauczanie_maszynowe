{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c312071-214b-4474-9da9-6f773316922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Normalize\n",
    "from collections import namedtuple\n",
    "import torch.nn as nn\n",
    "\n",
    "#importing Technical Analysis tools\n",
    "from ta import trend\n",
    "from ta import volatility\n",
    "from ta import momentum\n",
    "\n",
    "import utils\n",
    "from utils import return_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fab16f-fbc2-4909-a142-bbe4fcc63cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters=pd.read_csv(\"data/reut_data.csv\",sep='|')\n",
    "sx5e_data=pd.read_csv(\"data\\SX5E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8cdbc3-cab9-4fff-9ebb-92ca6b945cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48694\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ta\\trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "c:\\users\\48694\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ta\\trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "sx5e_data = sx5e_data.sort_index(axis=0 ,ascending=False)\n",
    "sx5e_data.reset_index(drop=True,inplace=True)\n",
    "sx5e_data['Date']=pd.to_datetime(sx5e_data.Date)\n",
    "\n",
    "sx5e_data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "adi=trend.ADXIndicator(close=sx5e_data[' Close'],high=sx5e_data[' High'],low=sx5e_data[' Low'])\n",
    "m_acd=trend.MACD(close=sx5e_data[' Close'])\n",
    "\n",
    "r_si=momentum.RSIIndicator(close=sx5e_data[' Close'])\n",
    "stochastic_oscilator=momentum.StochasticOscillator(close=sx5e_data[' Close'],high=sx5e_data[' High'],low=sx5e_data[' Low'])\n",
    "williamsr=momentum.WilliamsRIndicator(high=sx5e_data[' High'],low=sx5e_data[' Low'],close=sx5e_data[' Close'])\n",
    "\n",
    "bollinger=volatility.BollingerBands(close=sx5e_data[' Close'])\n",
    "atr=volatility.AverageTrueRange(high=sx5e_data[' High'],low=sx5e_data[' Low'],close=sx5e_data[' Close'])\n",
    "\n",
    "exponential_moving_avarge9=trend.EMAIndicator(close=sx5e_data[' Close'],window=9)\n",
    "exponential_moving_avarge18=trend.EMAIndicator(close=sx5e_data[' Close'],window=18)\n",
    "exponential_moving_avarge30=trend.EMAIndicator(close=sx5e_data[' Close'],window=30)\n",
    "\n",
    "sx5e_data['ADX']=adi.adx()\n",
    "sx5e_data['MACD']=m_acd.macd()\n",
    "sx5e_data['RSI']=r_si.rsi()\n",
    "sx5e_data['Stoch Osc']=stochastic_oscilator.stoch()\n",
    "sx5e_data['Williams R']=williamsr.williams_r()\n",
    "sx5e_data['Bollinger High band']=bollinger.bollinger_hband()\n",
    "sx5e_data['Bolinger Low Band']=bollinger.bollinger_lband()\n",
    "sx5e_data['ATR']=atr.average_true_range()\n",
    "sx5e_data['EMA9']=exponential_moving_avarge9.ema_indicator()\n",
    "sx5e_data['EMA18']=exponential_moving_avarge18.ema_indicator()\n",
    "sx5e_data['EMA30']=exponential_moving_avarge30.ema_indicator()\n",
    "sx5e_data.dropna(inplace=True)\n",
    "ret_fun=return_fun(sx5e_data,1,4)\n",
    "sx_ret=sx5e_data.copy()\n",
    "sx_ret['Ret']=ret_fun\n",
    "sx_ret.drop(columns=['ADX','MACD','RSI','Stoch Osc','Williams R','Bollinger High band','Bolinger Low Band','ATR','EMA9','EMA18','EMA30',' Open',' High',' Low'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b20fbd-e7b3-427c-be83-a5c4fcd5753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.drop(columns='column1',inplace=True)\n",
    "reuters.drop_duplicates(subset =\"Headline\",\n",
    "                     keep = 'first', inplace = True)\n",
    "reuters.dropna(inplace=True)\n",
    "reuters.reset_index(drop=True,inplace=True)\n",
    "\n",
    "for i in range(len(reuters)):\n",
    "    text=reuters['Headline'][i]\n",
    "    text=text.replace(\"REFILE-UPDATE 2-\",\"\")\n",
    "    text=text.replace(\"UPDATE 2-\",\"\")\n",
    "    text=text.replace(\"UPDATE 1-\",\"\")\n",
    "    text=text.replace(\"UPDATE \",\"\")\n",
    "    text=text.replace(\",\",\"\")\n",
    "    text=text.replace(\".\",\"\")\n",
    "    text=text.replace(\";\",\"\")\n",
    "    text=text.replace(\":\",\"\")\n",
    "    text=text.replace(\"-\",\"\")\n",
    "    text=text.replace(\"European\",\"\")\n",
    "    reuters['Headline'][i]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95e31f2-b574-456e-a343-3d5faf20007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx5e_data.drop(columns='Date',inplace=True)\n",
    "sx5e_data.drop(sx5e_data.tail(1).index,inplace=True)\n",
    "sx5e_tensor=torch.tensor(sx5e_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b2bdce-36f4-4ad4-99a6-8592edf6eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9221, -0.9442, -1.0001,  ..., -0.9280, -0.8126, -0.7074],\n",
      "        [-0.9531, -0.9766, -0.9926,  ..., -0.9452, -0.8345, -0.7281],\n",
      "        [-0.9801, -0.9924, -0.9511,  ..., -0.9550, -0.8519, -0.7462],\n",
      "        ...,\n",
      "        [ 2.1637,  2.3829,  2.2003,  ...,  2.2373,  2.3354,  2.4011],\n",
      "        [ 2.4110,  2.4069,  2.3607,  ...,  2.2597,  2.3400,  2.4022],\n",
      "        [ 2.3454,  2.3174,  2.2942,  ...,  2.2670,  2.3384,  2.3997]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean=torch.mean(sx5e_tensor,dim=0)\n",
    "std=torch.std(sx5e_tensor,dim=0)\n",
    "sx5e_norm=(sx5e_tensor-mean)/std\n",
    "print(sx5e_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ea230f-1da0-498f-a339-cf9cac22a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_fun.remove(None)\n",
    "tensor_ret=torch.tensor(ret_fun,dtype=torch.float32)\n",
    "mean_ret=torch.mean(tensor_ret)\n",
    "std_ret=torch.std(tensor_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3534f6-5f2f-4146-a892-8db430f19265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_ret.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be622065-20a7-4f25-a382-7446184daf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3076, 15])\n",
      "(3076, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sx5e_norm.shape)\n",
    "print(sx_ret.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a4baa8-58e0-405b-b4b3-d23bd9d56d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lang=utils.Lang('t')\n",
    "\n",
    "for i in range(len(reuters)):\n",
    "    sentence=reuters['Headline'][i]\n",
    "    lang.addSentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d42d0e-41e8-41df-97a5-392a055ec773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=[]\n",
    "prediction_days=5\n",
    "\n",
    "d=namedtuple('d',['headline','numeric'])\n",
    "data=namedtuple('Data',['data','target'])\n",
    "for i in range(len(reuters)):\n",
    "    headline=utils.tensorFromSentence(lang,reuters['Headline'][i])\n",
    "    row=sx_ret.loc[sx_ret['Date']== reuters['Date'][i]]\n",
    "    idx=row.index\n",
    "    if(idx.empty):\n",
    "        continue\n",
    "    if(idx-29-prediction_days <0):\n",
    "        continue\n",
    "    numeric=sx5e_norm[idx[0]-29-5 : idx[0]-29]\n",
    "    ret=row['Ret']\n",
    "    if(ret.empty):\n",
    "        continue\n",
    "    ret=torch.tensor(ret.values)\n",
    "    r=(ret-mean_ret)/std_ret\n",
    "    d1=d(headline,numeric)\n",
    "    da=data(d1,r)\n",
    "    data_set.append(da)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97dd9578-85ce-4360-8051-f07c25b468c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224\n",
      "1616\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "train_data=data_set[3232:]\n",
    "val_data=data_set[1616:3232]\n",
    "test_data=data_set[:1616]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806043fa-8067-4b23-b697-24b2a7b5e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0].data.numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e9bdef-3240-4c95-98f7-3a5fc68037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_data, batch_size=1,shuffle=True)\n",
    "val_loader=torch.utils.data.DataLoader(val_data, batch_size=1)\n",
    "test_loader=torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4e1f9a-a1ec-41bb-a151-f462007cb51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 15])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    print(x.numeric.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b7fa82-d6a2-49b9-ae06-117074f4dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TextAndNumeric\n",
    "from utils import correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237872fa-88aa-4e35-b6c6-e3eb58eb33ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Progress:  0% Loss: 0.065\n",
      "Epoch: 1 Progress: 11% Loss: 1.036\n",
      "Epoch: 1 Progress: 22% Loss: 1.043\n",
      "Epoch: 1 Progress: 33% Loss: 1.062\n",
      "Epoch: 1 Progress: 43% Loss: 1.057\n",
      "Epoch: 1 Progress: 54% Loss: 1.087\n",
      "Epoch: 1 Progress: 65% Loss: 1.100\n",
      "Epoch: 1 Progress: 76% Loss: 1.094\n",
      "Epoch: 1 Progress: 87% Loss: 1.106\n",
      "Epoch: 1 Progress: 98% Loss: 1.107\n",
      "\n",
      "Epoch:  1  Train Loss:  1.107 Train Acc: 0.50455\n",
      "Val loss: 0.891 Val Acc 0.49505\n",
      "\n",
      "Epoch: 2 Progress:  0% Loss: 0.528\n",
      "Epoch: 2 Progress: 11% Loss: 0.952\n",
      "Epoch: 2 Progress: 22% Loss: 1.015\n",
      "Epoch: 2 Progress: 33% Loss: 1.044\n",
      "Epoch: 2 Progress: 43% Loss: 1.022\n",
      "Epoch: 2 Progress: 54% Loss: 1.057\n",
      "Epoch: 2 Progress: 65% Loss: 1.073\n",
      "Epoch: 2 Progress: 76% Loss: 1.080\n",
      "Epoch: 2 Progress: 87% Loss: 1.097\n",
      "Epoch: 2 Progress: 98% Loss: 1.107\n",
      "\n",
      "Epoch:  2  Train Loss:  1.103 Train Acc: 0.50141\n",
      "Val loss: 0.870 Val Acc 0.48267\n",
      "\n",
      "Epoch: 3 Progress:  0% Loss: 0.708\n",
      "Epoch: 3 Progress: 11% Loss: 1.129\n",
      "Epoch: 3 Progress: 22% Loss: 1.054\n",
      "Epoch: 3 Progress: 33% Loss: 1.140\n",
      "Epoch: 3 Progress: 43% Loss: 1.129\n",
      "Epoch: 3 Progress: 54% Loss: 1.106\n",
      "Epoch: 3 Progress: 65% Loss: 1.092\n",
      "Epoch: 3 Progress: 76% Loss: 1.082\n",
      "Epoch: 3 Progress: 87% Loss: 1.081\n",
      "Epoch: 3 Progress: 98% Loss: 1.084\n",
      "\n",
      "Epoch:  3  Train Loss:  1.083 Train Acc: 0.54597\n",
      "Val loss: 0.894 Val Acc 0.50433\n",
      "\n",
      "Epoch: 4 Progress:  0% Loss: 0.179\n",
      "Epoch: 4 Progress: 11% Loss: 0.926\n",
      "Epoch: 4 Progress: 22% Loss: 1.033\n",
      "Epoch: 4 Progress: 33% Loss: 1.017\n",
      "Epoch: 4 Progress: 43% Loss: 0.997\n",
      "Epoch: 4 Progress: 54% Loss: 1.027\n",
      "Epoch: 4 Progress: 65% Loss: 1.033\n",
      "Epoch: 4 Progress: 76% Loss: 1.048\n",
      "Epoch: 4 Progress: 87% Loss: 1.040\n",
      "Epoch: 4 Progress: 98% Loss: 1.039\n",
      "\n",
      "Epoch:  4  Train Loss:  1.038 Train Acc: 0.57372\n",
      "Val loss: 0.923 Val Acc 0.48948\n",
      "\n",
      "Epoch: 5 Progress:  0% Loss: 0.164\n",
      "Epoch: 5 Progress: 11% Loss: 1.090\n",
      "Epoch: 5 Progress: 22% Loss: 1.080\n",
      "Epoch: 5 Progress: 33% Loss: 1.031\n",
      "Epoch: 5 Progress: 43% Loss: 1.015\n",
      "Epoch: 5 Progress: 54% Loss: 1.010\n",
      "Epoch: 5 Progress: 65% Loss: 0.996\n",
      "Epoch: 5 Progress: 76% Loss: 0.987\n",
      "Epoch: 5 Progress: 87% Loss: 0.989\n",
      "Epoch: 5 Progress: 98% Loss: 1.000\n",
      "\n",
      "Epoch:  5  Train Loss:  0.999 Train Acc: 0.59356\n",
      "Val loss: 0.956 Val Acc 0.49505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_and_numeric=TextAndNumeric(lang.n_words,16,16,15).cuda()\n",
    "\n",
    "params = text_and_numeric.parameters()\n",
    "# for name, param in lstm_numeric.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(param.data) \n",
    "        \n",
    "loss_fn=torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params, lr=0.0015) \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
    "\n",
    "epoch = 5\n",
    "\n",
    "\n",
    "history_train_loss=[]\n",
    "history_val_loss=[]\n",
    "history_train_acc=[]\n",
    "history_val_acc=[]\n",
    "\n",
    "# main loop\n",
    "for e in range(1,epoch+1):\n",
    "    \n",
    "    train_losses=[]\n",
    "    train_acc=[]\n",
    "    \n",
    "    loss_buffer=[]\n",
    "    train_correct=0\n",
    "    \n",
    "    text_and_numeric.train()\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        headline,numeric = x\n",
    "        numeric=numeric.float()\n",
    "        headline=headline.cuda()\n",
    "        numeric=numeric.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = text_and_numeric(headline,numeric)\n",
    "        output=output.float()\n",
    "        y=y.float()\n",
    "        loss = loss_fn(output, y)     \n",
    "        train_correct+=correct(output,y,std_ret,mean_ret)\n",
    "        loss_buffer.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        if(i%1000==1):\n",
    "            print(f\"Epoch: {e} Progress: {100 * i/len(train_loader):2.0f}% Loss: {torch.mean(torch.tensor(loss_buffer)):.3f}\")\n",
    "        \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss=torch.mean(torch.tensor(loss_buffer))\n",
    "    history_train_loss.append(train_loss)\n",
    "    train_acc=train_correct/len(train_loader)\n",
    "    history_train_acc.append(train_acc)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(f\"Epoch:  {e}  Train Loss:  {train_loss:.3f} Train Acc: {train_acc:.5f}\")\n",
    "    \n",
    "    text_and_numeric.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_buffer=[]\n",
    "        val_ac=0\n",
    "        cor=0\n",
    "        for i, (x,y) in enumerate(val_loader):\n",
    "            headline,numeric = x\n",
    "            numeric=numeric.float()\n",
    "            headline=headline.cuda()\n",
    "            numeric=numeric.cuda()\n",
    "            y=y.cuda()\n",
    "            \n",
    "            output=text_and_numeric(headline,numeric)\n",
    "            output.float()\n",
    "            y.float()\n",
    "            val_loss_buffer.append(loss_fn(output,y).item())\n",
    "            \n",
    "            \n",
    "            cor+=correct(output,y,std_ret,mean_ret)\n",
    "            \n",
    "        val_acc=cor/len(val_loader)\n",
    "        val_loss=torch.mean(torch.tensor(val_loss_buffer))\n",
    "        print(f\"Val loss: {val_loss:.3f} Val Acc {val_acc:.5f}\")\n",
    "        print()\n",
    "        \n",
    "        history_val_loss.append(val_loss)\n",
    "        history_val_acc.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e06dde77-306c-41a5-8f5e-2c10917e5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_and_numeric,'models/text_and_numeric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a81124-cc16-49db-a37b-d2e460c84972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
