{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bce2b9-f5c3-4421-b2c0-d774fcc0466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Normalize\n",
    "from collections import namedtuple\n",
    "\n",
    "#importing Technical Analysis tools\n",
    "from ta import trend\n",
    "from ta import volatility\n",
    "from ta import momentum\n",
    "\n",
    "from utils import return_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eec1110-19be-4915-b713-7232ebf93a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e210bf6c-8305-4ddd-9a7f-bed33ca216f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx5e_data=pd.read_csv(\"data\\SX5E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8758be68-ee9c-41b5-bf05-8b84e707efff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/10/21</td>\n",
       "      <td>4198.18</td>\n",
       "      <td>4221.57</td>\n",
       "      <td>4178.66</td>\n",
       "      <td>4199.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/09/21</td>\n",
       "      <td>4242.66</td>\n",
       "      <td>4246.52</td>\n",
       "      <td>4201.85</td>\n",
       "      <td>4208.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/08/21</td>\n",
       "      <td>4273.32</td>\n",
       "      <td>4288.20</td>\n",
       "      <td>4233.09</td>\n",
       "      <td>4233.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/07/21</td>\n",
       "      <td>4157.72</td>\n",
       "      <td>4277.03</td>\n",
       "      <td>4157.72</td>\n",
       "      <td>4276.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/06/21</td>\n",
       "      <td>4095.39</td>\n",
       "      <td>4146.16</td>\n",
       "      <td>4078.64</td>\n",
       "      <td>4137.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date     Open     High      Low    Close\n",
       "0  12/10/21  4198.18  4221.57  4178.66  4199.16\n",
       "1  12/09/21  4242.66  4246.52  4201.85  4208.30\n",
       "2  12/08/21  4273.32  4288.20  4233.09  4233.09\n",
       "3  12/07/21  4157.72  4277.03  4157.72  4276.20\n",
       "4  12/06/21  4095.39  4146.16  4078.64  4137.11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx5e_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0478fac2-175f-49c8-9ecb-a86b1c93e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48694\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ta\\trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "c:\\users\\48694\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ta\\trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "sx5e_data = sx5e_data.sort_index(axis=0 ,ascending=False)\n",
    "sx5e_data.reset_index(drop=True,inplace=True)\n",
    "sx5e_data.drop(columns=['Date'],inplace=True)\n",
    "\n",
    "# sx5e_data['Return']=ret_fun\n",
    "sx5e_data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "adi=trend.ADXIndicator(close=sx5e_data[' Close'],high=sx5e_data[' High'],low=sx5e_data[' Low'])\n",
    "m_acd=trend.MACD(close=sx5e_data[' Close'])\n",
    "\n",
    "r_si=momentum.RSIIndicator(close=sx5e_data[' Close'])\n",
    "stochastic_oscilator=momentum.StochasticOscillator(close=sx5e_data[' Close'],high=sx5e_data[' High'],low=sx5e_data[' Low'])\n",
    "williamsr=momentum.WilliamsRIndicator(high=sx5e_data[' High'],low=sx5e_data[' Low'],close=sx5e_data[' Close'])\n",
    "\n",
    "bollinger=volatility.BollingerBands(close=sx5e_data[' Close'])\n",
    "atr=volatility.AverageTrueRange(high=sx5e_data[' High'],low=sx5e_data[' Low'],close=sx5e_data[' Close'])\n",
    "\n",
    "exponential_moving_avarge9=trend.EMAIndicator(close=sx5e_data[' Close'],window=9)\n",
    "exponential_moving_avarge18=trend.EMAIndicator(close=sx5e_data[' Close'],window=18)\n",
    "exponential_moving_avarge30=trend.EMAIndicator(close=sx5e_data[' Close'],window=30)\n",
    "\n",
    "sx5e_data['ADX']=adi.adx()\n",
    "sx5e_data['MACD']=m_acd.macd()\n",
    "sx5e_data['RSI']=r_si.rsi()\n",
    "sx5e_data['Stoch Osc']=stochastic_oscilator.stoch()\n",
    "sx5e_data['Williams R']=williamsr.williams_r()\n",
    "sx5e_data['Bollinger High band']=bollinger.bollinger_hband()\n",
    "sx5e_data['Bolinger Low Band']=bollinger.bollinger_lband()\n",
    "sx5e_data['ATR']=atr.average_true_range()\n",
    "sx5e_data['EMA9']=exponential_moving_avarge9.ema_indicator()\n",
    "sx5e_data['EMA18']=exponential_moving_avarge18.ema_indicator()\n",
    "sx5e_data['EMA30']=exponential_moving_avarge30.ema_indicator()\n",
    "sx5e_data.dropna(inplace=True)\n",
    "ret_fun=return_fun(sx5e_data,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8c5f6d-7f73-4414-9e09-0c547cf629ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3077\n",
      "3076\n",
      "tensor([-0.2160,  0.3504,  1.3764,  ..., -1.0081, -0.5856, -0.2172])\n"
     ]
    }
   ],
   "source": [
    "type(ret_fun[1])\n",
    "# tensor_return=torch.Tensor(ret_fun)\n",
    "print(len(ret_fun))\n",
    "ret_fun.remove(None)\n",
    "print(len(ret_fun))\n",
    "tensor_ret=torch.tensor(ret_fun,dtype=torch.float32)\n",
    "print(tensor_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a8a11e0-7758-4614-8b3b-08d08a1191f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=ret_fun\n",
    "plt.hist(x, bins=400)\n",
    "plt.ylim(0,70)\n",
    "plt.xlim(-5,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044086d8-45dd-4f60-bf07-127327b6920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx5e_data.drop(sx5e_data.tail(1).index,inplace=True)\n",
    "sx5e_tensor=torch.tensor(sx5e_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689b5d44-997d-4133-8fd7-c35a4f3640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx5e_data=torch.tensor(sx5e_data.values,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca165190-7462-4409-89f0-ea0a3e7945f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=torch.mean(sx5e_tensor,dim=0)\n",
    "std=torch.std(sx5e_tensor,dim=0)\n",
    "sx5e_norm=(sx5e_tensor-mean)/std\n",
    "# print(sx5e_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fdddf3-4324-4cc3-a18e-45a1a892c818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2078, 15])\n",
      "torch.Size([499, 15])\n",
      "torch.Size([499, 15])\n"
     ]
    }
   ],
   "source": [
    "train=sx5e_norm[998:]\n",
    "\n",
    "val=sx5e_norm[499:998]\n",
    "test=sx5e_norm[:499]\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# print(train[2077])\n",
    "# print(val[498])\n",
    "# print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3e6233-ac28-4cbb-86ed-a6b0428e2e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1859,  0.2549,  1.0534,  ..., -0.8024, -0.4736, -0.1868])\n"
     ]
    }
   ],
   "source": [
    "mean_ret=torch.mean(tensor_ret)\n",
    "std_ret=torch.std(tensor_ret)\n",
    "ret_norm=(tensor_ret-mean_ret)/std_ret\n",
    "print(ret_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201d568f-15c3-4edd-b90e-8d952da29711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x000001EAF63ABD80>\n",
      "torch.Size([499])\n",
      "torch.Size([499])\n"
     ]
    }
   ],
   "source": [
    "train_target=ret_norm[998:]\n",
    "val_target=ret_norm[499:998]\n",
    "test_target=ret_norm[:499]\n",
    "\n",
    "print(train_target.type)\n",
    "print(val_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598f2f10-7305-4c22-8d2e-53327ff5c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=namedtuple('Data',['x','target'])\n",
    "prediction_days=5\n",
    "days_to_predict=1\n",
    "dataset=[]\n",
    "for i in range(len(sx5e_norm)-2):\n",
    "    end = i + prediction_days\n",
    "    out_end = end + days_to_predict\n",
    "\n",
    "    if(out_end>len(sx5e_norm)):\n",
    "        break\n",
    "    \n",
    "    \n",
    "    X=(sx5e_norm[i:end])\n",
    "    y=(tensor_ret[end])\n",
    "    d=data(X,y)\n",
    "    dataset.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8b7cbf-ae1d-4e1a-b646-d677c4930fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2073\n",
      "499\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataset))\n",
    "\n",
    "train_set=dataset[998:]\n",
    "val_set=dataset[499:998]\n",
    "test_set=dataset[:499]\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9c4247a-8a9d-41f9-8f7c-5141451f3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_set, batch_size=128)\n",
    "val_loader=torch.utils.data.DataLoader(val_set, batch_size=64)\n",
    "test_loader=torch.utils.data.DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4159fd-c12f-4511-a801-8065a69093d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a260336f-da88-4f40-8f88-75b7b02b958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import LSTMNumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "029fdf0e-b675-429c-8320-8091c8cb0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1  Train Loss:  2.879 Train Acc: 0.48963\n",
      "Val loss: 1.357 Val Acc 0.47295\n",
      "\n",
      "\n",
      "Epoch:  2  Train Loss:  1.785 Train Acc: 0.49686\n",
      "Val loss: 1.509 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  3  Train Loss:  1.582 Train Acc: 0.51712\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  4  Train Loss:  1.512 Train Acc: 0.52822\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  5  Train Loss:  1.508 Train Acc: 0.51230\n",
      "Val loss: 1.341 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  6  Train Loss:  1.515 Train Acc: 0.50989\n",
      "Val loss: 1.354 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  7  Train Loss:  1.523 Train Acc: 0.50796\n",
      "Val loss: 1.349 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  8  Train Loss:  1.524 Train Acc: 0.50844\n",
      "Val loss: 1.337 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  9  Train Loss:  1.522 Train Acc: 0.50796\n",
      "Val loss: 1.331 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  10  Train Loss:  1.520 Train Acc: 0.50844\n",
      "Val loss: 1.331 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  11  Train Loss:  1.518 Train Acc: 0.51037\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  12  Train Loss:  1.516 Train Acc: 0.50796\n",
      "Val loss: 1.331 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  13  Train Loss:  1.517 Train Acc: 0.50651\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  14  Train Loss:  1.515 Train Acc: 0.50603\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  15  Train Loss:  1.516 Train Acc: 0.51230\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  16  Train Loss:  1.514 Train Acc: 0.51037\n",
      "Val loss: 1.331 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  17  Train Loss:  1.513 Train Acc: 0.50748\n",
      "Val loss: 1.333 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  18  Train Loss:  1.515 Train Acc: 0.50169\n",
      "Val loss: 1.335 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  19  Train Loss:  1.516 Train Acc: 0.50651\n",
      "Val loss: 1.334 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  20  Train Loss:  1.518 Train Acc: 0.50555\n",
      "Val loss: 1.335 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  21  Train Loss:  1.518 Train Acc: 0.50796\n",
      "Val loss: 1.339 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  22  Train Loss:  1.521 Train Acc: 0.50458\n",
      "Val loss: 1.339 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  23  Train Loss:  1.521 Train Acc: 0.50748\n",
      "Val loss: 1.336 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  24  Train Loss:  1.519 Train Acc: 0.50603\n",
      "Val loss: 1.343 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  25  Train Loss:  1.521 Train Acc: 0.51423\n",
      "Val loss: 1.352 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  26  Train Loss:  1.524 Train Acc: 0.50217\n",
      "Val loss: 1.357 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  27  Train Loss:  1.524 Train Acc: 0.50844\n",
      "Val loss: 1.357 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  28  Train Loss:  1.523 Train Acc: 0.50699\n",
      "Val loss: 1.360 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  29  Train Loss:  1.522 Train Acc: 0.50844\n",
      "Val loss: 1.365 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  30  Train Loss:  1.521 Train Acc: 0.52195\n",
      "Val loss: 1.355 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  31  Train Loss:  1.518 Train Acc: 0.51809\n",
      "Val loss: 1.347 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  32  Train Loss:  1.513 Train Acc: 0.52436\n",
      "Val loss: 1.344 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  33  Train Loss:  1.512 Train Acc: 0.52050\n",
      "Val loss: 1.338 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  34  Train Loss:  1.508 Train Acc: 0.52243\n",
      "Val loss: 1.335 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  35  Train Loss:  1.507 Train Acc: 0.52822\n",
      "Val loss: 1.333 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  36  Train Loss:  1.506 Train Acc: 0.51520\n",
      "Val loss: 1.332 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  37  Train Loss:  1.505 Train Acc: 0.52967\n",
      "Val loss: 1.332 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  38  Train Loss:  1.505 Train Acc: 0.53256\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  39  Train Loss:  1.504 Train Acc: 0.52388\n",
      "Val loss: 1.328 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  40  Train Loss:  1.502 Train Acc: 0.53063\n",
      "Val loss: 1.330 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  41  Train Loss:  1.502 Train Acc: 0.52967\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  42  Train Loss:  1.501 Train Acc: 0.52243\n",
      "Val loss: 1.328 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  43  Train Loss:  1.501 Train Acc: 0.52147\n",
      "Val loss: 1.328 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  44  Train Loss:  1.501 Train Acc: 0.52822\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  45  Train Loss:  1.500 Train Acc: 0.52774\n",
      "Val loss: 1.328 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  46  Train Loss:  1.500 Train Acc: 0.53015\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  47  Train Loss:  1.499 Train Acc: 0.52726\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  48  Train Loss:  1.499 Train Acc: 0.53690\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  49  Train Loss:  1.499 Train Acc: 0.53256\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  50  Train Loss:  1.498 Train Acc: 0.52677\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  51  Train Loss:  1.498 Train Acc: 0.53449\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  52  Train Loss:  1.498 Train Acc: 0.53449\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  53  Train Loss:  1.498 Train Acc: 0.52918\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  54  Train Loss:  1.498 Train Acc: 0.53739\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  55  Train Loss:  1.497 Train Acc: 0.52677\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  56  Train Loss:  1.497 Train Acc: 0.52918\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  57  Train Loss:  1.497 Train Acc: 0.52774\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  58  Train Loss:  1.497 Train Acc: 0.53401\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  59  Train Loss:  1.497 Train Acc: 0.52098\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  60  Train Loss:  1.497 Train Acc: 0.54028\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  61  Train Loss:  1.497 Train Acc: 0.52629\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  62  Train Loss:  1.497 Train Acc: 0.53401\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  63  Train Loss:  1.496 Train Acc: 0.53208\n",
      "Val loss: 1.326 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  64  Train Loss:  1.496 Train Acc: 0.53401\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  65  Train Loss:  1.496 Train Acc: 0.53208\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  66  Train Loss:  1.496 Train Acc: 0.54124\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  67  Train Loss:  1.496 Train Acc: 0.54173\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  68  Train Loss:  1.496 Train Acc: 0.53787\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  69  Train Loss:  1.496 Train Acc: 0.53932\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  70  Train Loss:  1.496 Train Acc: 0.53497\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  71  Train Loss:  1.496 Train Acc: 0.53883\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  72  Train Loss:  1.496 Train Acc: 0.53690\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  73  Train Loss:  1.496 Train Acc: 0.54269\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  74  Train Loss:  1.496 Train Acc: 0.54028\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n",
      "\n",
      "Epoch:  75  Train Loss:  1.496 Train Acc: 0.53787\n",
      "Val loss: 1.327 Val Acc 0.52705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_numeric=LSTMNumeric(15,30).cuda()\n",
    "params = lstm_numeric.parameters()\n",
    "# for name, param in lstm_numeric.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(param.data) \n",
    "        \n",
    "loss_fn=torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params, lr=0.06) \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "# we will train for only a single epoch \n",
    "epoch = 75\n",
    "\n",
    "\n",
    "history_train_loss=[]\n",
    "history_val_loss=[]\n",
    "history_train_acc=[]\n",
    "\n",
    "# main loop\n",
    "for e in range(1,epoch+1):\n",
    "    \n",
    "    train_losses=[]\n",
    "    train_acc=[]\n",
    "    loss_buffer=[]\n",
    "    running_loss=0\n",
    "    corr=0\n",
    "    size=0\n",
    "    \n",
    "    lstm_numeric.train()\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        size+=len(y)\n",
    "        x=x.float()\n",
    "        y=y.float()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = lstm_numeric(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "        corr+=correct(output,y,std_ret,mean_ret)\n",
    "        loss_buffer.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss=torch.mean(torch.tensor(loss_buffer))\n",
    "    history_train_loss.append(train_loss)\n",
    "    train_acc=corr/size\n",
    "    print()\n",
    "    print(f\"Epoch:  {e}  Train Loss:  {train_loss:.3f} Train Acc: {train_acc:.5f}\")\n",
    "    \n",
    "    lstm_numeric.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss_buffer=[]\n",
    "        val_ac=0\n",
    "        size=0\n",
    "        cor=0\n",
    "        for i, (x,y) in enumerate(val_loader):\n",
    "            x=x.float()\n",
    "            y=y.float()\n",
    "            \n",
    "            x=x.cuda()\n",
    "            y=y.cuda()\n",
    "            \n",
    "            output=lstm_numeric(x)\n",
    "            val_loss_buffer.append(loss_fn(output,y).item())\n",
    "            cor+=correct(output,y,std_ret,mean_ret)\n",
    "            size+=len(y)\n",
    "        val_acc=cor/size\n",
    "        val_loss=torch.mean(torch.tensor(val_loss_buffer))\n",
    "        print(f\"Val loss: {val_loss:.3f} Val Acc {val_acc:.5f}\")\n",
    "        print()\n",
    "        \n",
    "        history_val_loss.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b62863b-8f56-468e-b860-65428528ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_numeric,'models/lstm_numeric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef73ff-905f-4acb-a65c-f619e44a0734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
